# ğŸ“š PaperMind - AI-Powered Research Paper Analysis

<div align="center">

![PaperMind Banner](https://img.shields.io/badge/PaperMind-AI%20Research%20Assistant-8b5cf6?style=for-the-badge&logo=bookstack&logoColor=white)

[![Python](https://img.shields.io/badge/Python-3.9+-3776ab?style=flat-square&logo=python&logoColor=white)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-ff4b4b?style=flat-square&logo=streamlit&logoColor=white)](https://streamlit.io)
[![LangChain](https://img.shields.io/badge/LangChain-0.1.20-1c3c3c?style=flat-square)](https://langchain.com)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4-412991?style=flat-square&logo=openai&logoColor=white)](https://openai.com)
[![License](https://img.shields.io/badge/License-MIT-green?style=flat-square)](LICENSE)

**Transform how you read research papers with AI-powered analysis**

[Live Demo](#demo) â€¢ [Features](#features) â€¢ [Installation](#installation) â€¢ [Usage](#usage)

</div>

---

## ğŸ¯ Problem Statement

Reading research papers is challenging due to:
- ğŸ“– **Technical Jargon**: Unfamiliar domain-specific terms and acronyms
- ğŸ“ **Complex Equations**: Mathematical formulas without clear explanations
- ğŸ“Š **Dense Figures**: Charts and tables that need interpretation
- ğŸ“„ **Information Overload**: Long documents with scattered insights

**PaperMind solves these pain points** by providing an intelligent AI assistant that helps you understand any research paper quickly and thoroughly.

---

## âœ¨ Features

### ğŸ” Smart Document Analysis
- **Automatic Section Detection**: Identifies Abstract, Introduction, Methods, Results, etc.
- **Technical Term Glossary**: Auto-detects jargon with AI-powered definitions
- **Figure & Table Extraction**: Lists all visual elements with explanations
- **Citation Analysis**: Tracks most referenced works

### ğŸ“ Equation Explainer
- **Step-by-Step Breakdown**: Explains mathematical formulas in plain English
- **Variable Definitions**: Defines each symbol and its meaning
- **Context-Aware**: Uses paper context for accurate explanations

### ğŸ’¬ Intelligent Q&A
- **Natural Language Queries**: Ask questions in plain English
- **Three Explanation Levels**: Brief, Detailed, or Expert responses
- **Source Citations**: Every answer includes relevant passages
- **Persistent Chat**: Conversation history maintained throughout session

### âš¡ Quick Actions
- **Summarize**: Get paper overview in seconds
- **Key Takeaways**: Extract main findings
- **Prerequisites**: Identify required background knowledge
- **Explain Equations**: Break down all mathematical content

### ğŸ¨ Professional Dark Theme UI
- Modern, eye-friendly dark interface
- Three-panel layout for efficient navigation
- Reading progress tracking
- Export chat history as JSON

---

## ğŸ–¼ï¸ Screenshots

<div align="center">

| Welcome Screen | Document Analysis |
|:---:|:---:|
| Upload papers and get started | View sections, terms, and figures |

| AI Chat | Equation Explainer |
|:---:|:---:|
| Ask questions, get cited answers | Step-by-step math breakdowns |

</div>

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.9+
- OpenAI API Key

### Installation

```bash
# Clone the repository
git clone https://github.com/rajeshwar-vempaty/PDF_Info_Retrieval.git
cd PDF_Info_Retrieval

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set up environment
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY
```

### Run the App

```bash
# Standard version
streamlit run app.py

# Enhanced version with dark theme
streamlit run app_enhanced.py
```

Visit `http://localhost:8501` in your browser.

---

## ğŸ“ Project Structure

```
PDF_Info_Retrieval/
â”œâ”€â”€ app.py                      # Standard Streamlit application
â”œâ”€â”€ app_enhanced.py             # Enhanced version with dark theme
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ .env.example               # Environment template
â”‚
â”œâ”€â”€ src/                       # Source modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py              # Configuration settings
â”‚   â”œâ”€â”€ pdf_processor.py       # PDF text extraction
â”‚   â”œâ”€â”€ text_processor.py      # Text cleaning & chunking
â”‚   â”œâ”€â”€ vector_store.py        # FAISS vector store
â”‚   â”œâ”€â”€ conversation.py        # LangChain conversation
â”‚   â”œâ”€â”€ document_analyzer.py   # Basic document analysis
â”‚   â”œâ”€â”€ paper_analyzer.py      # Advanced paper analysis
â”‚   â”‚
â”‚   â””â”€â”€ ui/                    # UI components
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ templates.py       # Chat templates
â”‚       â””â”€â”€ dark_theme.py      # Dark theme styling
â”‚
â”œâ”€â”€ tests/                     # Test suite
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ .streamlit/
    â””â”€â”€ config.toml            # Streamlit configuration
```

---

## ğŸ”§ Configuration

| Parameter | Default | Description |
|-----------|---------|-------------|
| `chunk_size` | 1500 | Text chunk size for processing |
| `llm_model_name` | gpt-3.5-turbo | OpenAI model to use |
| `llm_temperature` | 0.7 | Response creativity (0-1) |
| `embedding_model_type` | openai | Embedding model type |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PaperMind                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   PDF    â”‚â”€â”€â”€â–¶â”‚  Text    â”‚â”€â”€â”€â–¶â”‚  Vector  â”‚â”€â”€â”€â–¶â”‚  FAISS   â”‚  â”‚
â”‚  â”‚ Processorâ”‚    â”‚ Processorâ”‚    â”‚  Store   â”‚    â”‚  Index   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                        â”‚         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚         â”‚
â”‚  â”‚  Paper   â”‚    â”‚ Document â”‚    â”‚   Dark   â”‚         â”‚         â”‚
â”‚  â”‚ Analyzer â”‚    â”‚ Analyzer â”‚    â”‚  Theme   â”‚         â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚         â”‚
â”‚       â”‚               â”‚               â”‚               â”‚         â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                               â”‚                                  â”‚
â”‚                               â–¼                                  â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                    â”‚   Conversation   â”‚                         â”‚
â”‚                    â”‚     Manager      â”‚                         â”‚
â”‚                    â”‚   (LangChain)    â”‚                         â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                               â”‚                                  â”‚
â”‚                               â–¼                                  â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                    â”‚   OpenAI GPT    â”‚                          â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# With coverage report
pytest --cov=src --cov-report=html

# Specific test file
pytest tests/test_paper_analyzer.py -v
```

---

## ğŸŒ Deployment

### Streamlit Cloud

1. Push code to GitHub
2. Visit [share.streamlit.io](https://share.streamlit.io)
3. Connect your repository
4. Add secrets in Streamlit Cloud dashboard:
   ```toml
   OPENAI_API_KEY = "your-api-key"
   ```
5. Deploy!

### Docker

```bash
docker build -t papermind .
docker run -p 8501:8501 -e OPENAI_API_KEY=your-key papermind
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [LangChain](https://langchain.com/) - LLM application framework
- [Streamlit](https://streamlit.io/) - Web application framework
- [OpenAI](https://openai.com/) - Language models
- [FAISS](https://github.com/facebookresearch/faiss) - Vector similarity search

---

<div align="center">

**Built with â¤ï¸ by [Rajeshwar Vempaty](https://github.com/rajeshwar-vempaty)**

â­ Star this repo if you find it helpful!

</div>
